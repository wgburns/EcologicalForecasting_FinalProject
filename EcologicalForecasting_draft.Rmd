---
title: "Examining drivers of cyanobacteria blooms in two shallow, eutrophic bays in Lake Champlain"
author: "Wilton Burns, Herman Njoroge Chege, and Mahalia Clark"
date: "12/2/2019"
output: 
  pdf_document:
    citation_package: natbib
bibliography: EcologicalForecastingRefs.bib
csl: limnology-and-oceanography.csl
editor_options: 
  chunk_output_type: console
---

## 1. Introduction 

GENERAL NOTES:  

* why important to study? 
* cite a few other studies doing similar work 
* end intro with "in this study" paragraph to set up reader to how we plan to attack the problem 
* hypotheses? 
* Figs for this section: 
  + map of study area 
  + bar graph of cyanobacteria bloom timing being different every year (long-term monitoring)
  
Anthropogenic eutrophication of natural water bodies, meaning increased nutrient concentration due to human activities, is a global phenomenon that often leads to higher rates of primary production and decreased utility of aquatic ecosystems (@reynolds_cyanobacterial_1987; @paerl_nuisance_1988; @paerl_controlling_2011). Eutrophication, coupled with warmer temperatures and higher CO2 concentrations, has caused increases in cyanobacteria blooms, a type of potentially toxic prokaryotic plankton, in coastal oceans, some parts of the Laurentian Great Lakes, and thousands of inland lakes and ponds (@paerl_harmful_2001, @paerl_controlling_2011; @paerl_blooms_2008). Phytoplankton play an integral role as the base of aquatic food webs in both freshwater and marine systems, however, when cyanobacteria growth is unchecked, blooms can be detrimental to organisms living in and around freshwater ecosystems and often cause problems that propagate up the food web (@karjalainen_ecosystem_2007, @arend_seasonal_2010). The climate is changing and environmental conditions are becoming more favorable for bloom-forming harmful cyanobacteria (@johnk_summer@2006; @paerl_blooms_2008; @jeppesen_climate_2011; @huisman_cyanobacterial_2018). Therefore, it is becoming increasingly important to understand cyanobacteria bloom onset and senescence. Understanding why and when severe cyanobacteria blooms occur will help inform mitigation efforts. 

### 1.1 Factors that drive cyanobacteria blooms 

**Goal with this section: Develop what is known from what is not known or what has conflicting attributions (and why), and how this leads you to your research question. This driver – that is, different watersheds and connectivity – needs to be developed in the Intro to show the reader this is a valid research question/hypothesis to pursue.**

- Eutrophication (can mention watershed bay interactions in this section)
- Warm temperatures
- Water column stratification (leads to internal loading of nutrients)
- Increased CO2 in the atmosphere (some types of cyanobacteria more efficiently produce organic matter 
- Rain and wind events (mix up water column prohibiting internal loading of nutrients and also giving advantage to larger phytoplankton, like diatoms, that need turbulence to get mixed up into the photic zone)
- Cyanobacteria are physiologically diverse and have developed multiple strategies to out compete other types of phytoplankton: N-fixation, CO2 concentrating mechanisms, buoyancy regulation, toxin production, predator avoidance 
- Top-down grazing by zooplankton – however, many studies have shown that cyanobacteria often avoid grazing by forming dense colonies and toxin production (DeMott 1986; Lemaire et al. 2012)
- Viral lysis or fungal infection – often don’t result in long-lasting effects on cyanobacteria populations (Yoshida et al. 2008; Van Wichelen et al. 2016)
- Filter feeders like mussels - effect they have on cyanobacteria blooms is lake-specific (Reeders et al. 1989; Vanderploeg et al. 2001)
- Competition from other, non-harmful, phytoplankton 

How does lake size (area/depth) affect which drivers may be relatively important (shallow vs deep)? Lake trophic status? 


## 2. Methods 

### 2.1 study sites

Missisquoi (MB) and St. Albans (SA) bays are both shallow eutrophic bays 18 km apart in the Northeastern part of Lake Champlain (Fig. 1). MB and SA were chosen for this study because both started experiencing anthropogenic eutrophication in the early 20th century and frequently have cyanobacteria blooms in the late summer months (@levine_eutrophication_2011). Their proximity to one another and their differing geomorphometry make this an interesting comparison of how external factors influence the timing and severity of cyanobacteria blooms. Surface area of MB is ten times greater than SA (77.5 ha and 7 ha, respectively). 

### 2.2 High-frequency data   

YSI monitoring platforms were deployed in MB and SA from late spring to late fall in 2017 and 2018. One platform was moored in MB (N 44˚59.511’, W 073˚06.777’) and equipped with a YSI 6-series sonde with sensors to measure water temperature, specific conductivity, optical dissolved oxygen, pH, phycocyanin, and chlorophyll a. Per recommendation from YSI, freshly calibrated 6-series sondes were swapped out every 4 to 6 weeks and cross-checked for continuity between sensors. Two platforms were moored in SA (one in the shallower, northeastern portion of SA, N 44˚47.588’, W 073˚09.308’, and one in the deeper, southern portion of the bay, N 44˚46.403’, W 073˚10.469’). In SA, the monitoring platforms were equipped with YSI EXO2 sondes with sensors that measured water temperature, conductivity, optical dissolved oxygen, pH, and phycocyanin/chlorophyll a. Per recommendation from YSI, pH and optical dissolved oxygen sensors were calibrated every 90 days. At all three sites, hourly depth profiles were made at 0.5 m increments. Profiles started 0.5 m from the surface and went down to ~1 m off the bottom sediment (bottom depth varied throughout the summer and at each monitoring station depending on lake water level). The difference between surface water tempertaure and bottom water temperature (\Delta Temperature) was calculated for each hourly profile and used as a proxy for stratification.

River discharge data was obtained from USGS gages in both the Missisquoi (Station 0429400, Missisquoi River at Swanton, Vermont) and St. Albans (Station 04292810, Jewett Brook near St. Albans, Vermont) watersheds. Meteorological data was obtained using a a HOBO RX3000 remote monitoring station data logger (Onset Computer Corporation, 470 MacArthur Blvd., Bourne, MA 02532) deployed at the outer YSI water quality monitoring station in SA. Data was collected every 1 min - 15 min on wind speed and direction, air temperature, and solar radiation. 
  
```{r, message = F, echo = F, out.width = "75%", fig.align="center", fig.cap = "Bathymetric map of Missisquoi and St. Albans Bays with the associated watersheds outlined in green and pink, respectively. Yellow triangles indicate Vermont EPSCoR high-frequency monitoring stations. Black dots indicate Vermont DEC long-term monitoring stations. The largest rivers flowing into Missisquoi Bay (Missisquoi, Rock, and Pike Rivers) are labeled and the two largest brooks flowing into St. Ablans Bay (Jewett and Stevens Brook) are labeled. Land use categories are depicted for each watershed." } 
library(knitr)

img1_path <- "data/Presentation_Map_EPSCOR_Lake_Sites2018-1-6.jpg"

include_graphics(img1_path)


```


### 2.2 Preparing data for analysis 

#### 2.2.1 Buoy sensor data  

*Since the buoys collect data at multiple depths, we first considered whether to focus exclusively on the sensors nearest the surface, or to aggregate data from whichever depth had the highest concentration of PC at a given time, so as to track a bloom as it moves up and down in the water column. For each bay and year, we explored how PC values varied with depth. First, for each bay and year, we used R to create a correlation matrix with Pearson correlation coefficients for the PC levels at each depth. We found PC levels across depths to be moderately to highly correlated in each case (0.38-1.00), indicating that PC levels near the surface would most likely be representative of those throughout the water column. We also used R to compare the PC levels across depths at each time point, and find out at what depth the PC level was maximized. We found that for periods of low PC levels, the maximum might be found at any depth, but for periods of high PC levels, such as during a cyanobacteria bloom, maximum PC levels where most often found near the surface. For these reasons,* we decided to limit ourselves to the data collected by sensors nearest the surface (0.5m depth), augmented with the deltaTemp as a measure of stratification. *See the the markdown file or pdf "Exploring_PC_Depths" for details.*

In order to run a forecasting model or look at feature importance with time lags, we needed to collapse this hourly data into daily data, so that daily cycles would not confound predictions or time lags. *We explored whether to use daily averages or daily maximums. R was used to calculate daily averages and maximums for each buoy variable, and to create time plots of the daily and hourly data. After inspecting the time plots,* we decided to use daily averages rather than daily maximums, as the later were unduly influenced by sudden brief peaks or high-valued outliers in the hourly data.

In addition to collapsing our hourly buoy data into daily averages for each environmental variable, we wanted to explore how water quality data related to PC values over different time lags. In order to include this lag, we used R to append the daily average PC levels 1-6 days in the future to the data for each time step.

*See pdf/Rmd "DailyTimeLags" for details*

#### 2.2.2 Meteorological and river discharge data 



### 2.3 Data analysis - feature importance 

Feature importance is a technique to understand the factors that most contribute to the mechanisms of a system. In our study we used XGBOOST a machine learning technique that has been shown to be most accurate in tabular and structured data. 

It uses gradient boosted decision trees and is built for speed and performance and hence is more accurate than alternatives. A benefit of using ensembles of decision tree methods like gradient boosting is that they can automatically provide estimates of feature importance from a trained predictive model. After we train the model we are then able to access the feature importances.

Generally, importance provides a score that indicates how useful or valuable each feature was in the construction of the boosted decision trees within the model. The more an attribute is used to make key decisions with decision trees, the higher its relative importance. This importance is calculated explicitly for each attribute in the data set, allowing attributes to be ranked and compared to each other.

Importance is calculated for a single decision tree by the amount that each attribute split point improves the performance measure, weighted by the number of observations the node is responsible for. The performance measure may be the purity (Gini index) used to select the split points or another more specific error function.The feature importances are then averaged across all of the the decision trees within the model @hastie2009elements. These features will help further down the road in developing a predictive model. 

## 3. Results  


### 3.1 Time Series

```{r, echo = F, message = F, warning= FALSE, fig.height = 6, fig.width = 7, fig.cap= "Timeseries of PC levels and environmental factors in MB. 2017: solid line. 2018: dashed line."}
#Load relevant packages
library(dplyr)
library(tidyr)
library(ggplot2)
#install.packages("padr")
library(padr)
library(zoo)

#Load Data
MB17 <- read.csv("data/mbAll17.csv", header = T) 
MB18 <- read.csv("data/mbAll18.csv", header = T)
SA17 <- read.csv("data/abAll17.csv", header = T)
SA18 <- read.csv("data/abAll18.csv", header = T)

#Fix Date Format
MB17 <- MB17 %>% 
  mutate(date = as.POSIXct(strptime(date, format = "%m/%d/%Y", tz = "Etc/GMT-4")))
MB17 <- pad(MB17, interval = "day")

MB18 <- MB18 %>% 
  mutate(date = as.POSIXct(strptime(date, format = "%m/%d/%Y", tz = "Etc/GMT-4")))
MB18 <- pad(MB18, interval = "day")

SA17 <- SA17 %>% 
  mutate(date = as.POSIXct(strptime(date, format = "%m/%d/%Y", tz = "Etc/GMT-4")))
SA17 <- pad(SA17, interval = "day")

SA18 <- SA18 %>% 
  mutate(date = as.POSIXct(strptime(date, format = "%m/%d/%Y", tz = "Etc/GMT-4")))
SA18 <- pad(SA18, interval = "day")

#Select&Rename
shorten <- function(df){
  newdf <- df %>% 
    select(c(date, "PCMean1",
                                     "DeltaTempMean",
                                     "discharge",
                                     "SpCondMean",
                                     "temp",
                                     "solar",
                                     "ws",
                                     "wd")) %>% 
    rename(PC = PCMean1,
         Strat = DeltaTempMean,
         Q = discharge,
         Sal = SpCondMean,
         Temp = temp,
         Sun = solar,
         WS = ws,
         WD = wd)
    return(newdf)
}

MB17_short <- shorten(MB17)
MB17_short$day <- strftime(MB17_short$date, format = "%j", tz = "Etc/GMT-4")
MB18_short <- shorten(MB18)
MB18_short$day <- strftime(MB18_short$date, format = "%j", tz = "Etc/GMT-4")

SA17_short <- shorten(SA17)
SA17_short$day <- strftime(SA17_short$date, format = "%j", tz = "Etc/GMT-4")
SA18_short <- shorten(SA18)
SA18_short$day <- strftime(SA18_short$date, format = "%j", tz = "Etc/GMT-4")

#Tidy
MB17_tidy <- gather(MB17_short, "PC":"WD", key = "Variable", value = "Value") 
MB18_tidy <- gather(MB18_short, "PC":"WD", key = "Variable", value = "Value") 
SA17_tidy <- gather(SA17_short, "PC":"WD", key = "Variable", value = "Value") 
SA18_tidy <- gather(SA18_short, "PC":"WD", key = "Variable", value = "Value") 

#Plot MB
ggplot(NULL, aes(x = day, y = Value, group = Variable, color = Variable)) +
  geom_line(data = MB17_tidy, show.legend = FALSE) + 
  geom_line(data = MB18_tidy, show.legend = FALSE, linetype = "dashed") + 
  labs(title = "MB") + xlab("Day of year") + 
  facet_grid(rows = "Variable", scales = "free_y", switch = "both") +
  scale_x_discrete(breaks = seq(120,310,30))+
  theme_light() 
```


```{r, echo = F, message = F, warning= FALSE, fig.height = 6, fig.width = 7, fig.cap= "Timeseries of PC levels and environmental factors in SA. 2017: solid line. 2018: dashed line."}
#Plot SA
ggplot(NULL, aes(x = day, y = Value, group = Variable, color = Variable)) +
  geom_line(data = SA17_tidy, show.legend = FALSE) + 
  geom_line(data = SA18_tidy, show.legend = FALSE, linetype = "dashed") + 
  labs(title = "SA") + xlab("Day of year") + 
  facet_grid(rows = "Variable", scales = "free_y", switch = "both") +
  scale_x_discrete(breaks = seq(120,310,30))+
  theme_light() 
```


*Ideally we should fix the parameter labels on these and include a key with solid vs dotted...*


### 3.2 Feature Importance Results

```{r, echo = F, message = F, warning= FALSE, fig.cap= "Feature importance with all  bays and years combined."}

library(ggplot2)
library(RColorBrewer)
library(dplyr)

results_2 <- read.csv("data/allCombined.csv") 

results_2 <- results_2 %>% 
  select(-c(X))

results_2 %>% 
  ggplot() +
  geom_bar(aes(x = as.factor(DayinFuture), y = FeatureImportance, fill = Parameter),
           stat = 'identity') +
  scale_y_continuous(limits = c(0, 1.01),
                     name = "Feature Importance") + 
  scale_fill_brewer(palette = "Paired", labels = c(Delta~"Temperature", "Discharge", "Solar radiation", "Specific conductivity", "Air temperature", "Wind direction", "Wind speed", "Year")) +
  xlab("Days in the Future") +
  #expand = c(0,0)) +
  theme_bw() +
  theme(
        axis.title = element_text(size = 12),
        axis.text = element_text(size =10, colour = "black"),
        legend.text = element_text(size = 10),
        legend.text.align = 0,
        axis.text.x = element_text(angle = 45, hjust = 1))


```


```{r, echo = F, message = F, warning= FALSE, fig.cap= "Feature importance for each bay with years combined."}

results_3 <- read.csv("data/Sep_bay.csv") 

results_3 <- results_3 %>% 
  select(-c(X))

results_3 %>% 
  ggplot() +
  geom_bar(aes(x = as.factor(DayinFuture), y = FeatureImportance, fill = Parameter),
           stat = 'identity') +
  scale_y_continuous(limits = c(0, 1.01),
                     name = "Feature Importance") + 
  scale_fill_brewer(palette = "Paired", labels = c(Delta~"Temperature", "Discharge", "Solar radiation", "Specific conductivity", "Air temperature", "Wind direction", "Wind speed", "Year"))+
  xlab("Days in the future")+
  #expand = c(0,0))+
  theme_bw()+
  theme(
        axis.title = element_text(size = 12),
        axis.text = element_text(size =10, colour = "black"),
        legend.text = element_text(size = 10),
        legend.text.align = 0,
        axis.text.x = element_text(angle = 45, hjust = 1))+
  facet_wrap(~bay, nrow = 2)


```


```{r, echo = F, message = F, warning= FALSE, fig.cap= "Feature importance for each year with bays combined."}

results_4 <- read.csv("data/Sep_year.csv") 

results_4 <- results_4 %>% 
  select(-c(X))

results_4 %>% 
  ggplot() +
  geom_bar(aes(x = as.factor(DayinFuture), y = FeatureImportance, fill = Parameter),
           stat = 'identity') +
  scale_y_continuous(limits = c(0, 1.01),
                     name = "Feature Importance") + 
  scale_fill_brewer(palette = "Paired", labels = c(Delta~"Temperature", "Discharge", "Solar radiation", "Specific conductivity", "Air temperature", "Wind direction", "Wind speed"))+
  xlab("Days in the future")+
  #expand = c(0,0))+
  theme_bw()+
  theme(
        axis.title = element_text(size = 12),
        axis.text = element_text(size =10, colour = "black"),
        legend.text = element_text(size = 10),
        legend.text.align = 0,
        axis.text.x = element_text(angle = 45, hjust = 1))+
  facet_wrap(~year, nrow = 2)


```


```{r, echo = F, message = F, warning= FALSE, fig.cap= "Feature importance for each  bay and year."}


results_1 <- read.csv("data/Sep_bay_and_year.csv") 

results_1 <- results_1 %>% 
  select(-c(X))

results_1 %>% 
  ggplot() +
  geom_bar(aes(x = as.factor(DayinFuture), y = FeatureImportance, fill = Parameter),
           stat = 'identity')+
  scale_y_continuous(limits = c(0, 1.01),
                     name = "Feature Importance") + 
  scale_fill_brewer(palette = "Paired", labels = c(Delta~"Temperature", "Discharge", "Solar radiation", "Specific conductivity", "Air temperature", "Wind direction", "Wind speed"))+
  xlab("Days in the future")+
  #expand = c(0,0))+
  theme_bw()+
  theme(
        axis.title = element_text(size = 12),
        axis.text = element_text(size =10, colour = "black"),
        legend.text = element_text(size = 10),
        legend.text.align = 0,
        axis.text.x = element_text(angle = 45, hjust = 1))+
  facet_wrap(~bay+year)

```


### 3.3 Correlations

*I made correlations matrices for pretty much every environmental parameter with the 7 time steps of PC data to look at trends of how correlations with PC change with increasing time lag... Sometimes they show similar trends as feature importance, but sometimes not. In theory I could summarize these correlations coefficients into a chart with environmental parameters by PC time steps, which could be interesting for looking at trends. I could even graph them! But I haven't yet because I don't know enough about the statistics behind correlation coefficients to know if I'm using them properly. Like do we need to normalize the data first? Probably? See All_the_correlations.Rmd/pdf for all the correlations. - MC*

- Made lots of correlation matrices. Not sure if they're statistically legit.

- Haven't summarized trends yet: match feature importance somtimes, not always

- Discharge and salinity are NOT correlated in MB, but ARE correlated in St. Albans.

## 4. Discussion 

- Feature importance with all  bays and years combined (Figure 1):
Discharge, solar radiation, and specific conductivity were the most important features for explaining contemporaneous PC levels, while air temperature, solar radiation and wind speed were most important for future PC levels. Year was an important feature, while Bay was not.


- Feature importance for each bay with years combined (Figure 2): 
Discharge was the dominant feature in AB. Solar radiation was somewhat important in the near-term, but became less so with increasing lag. $\Delta$ temperature was also somewhat important, particularly 2-5 days in the future. For MB, there was no single dominant feature. Discharge was most important for contemporaneous PC levels (0-1 days out), wind direction was most important in the near-term (2 days out), and specific conductivity was most important 4-6 days out. Air temperature was somewhat important throughout. Wind speed was somewhat important in the mid-term (particularly 2-4 days out), and $\Delta$ temperature was somewhat important for contemporaneous levels (0-1 day out).


- Feature importance for each year with bays combined (Figure 3): 
In 2017, discharge was the most important feature for explaining contemporaneous PC levels (0-1 days out). Air temperature and solar radiation were important in the mid-term (peaking in importance around 4 days out), and $\Delta$ temperature and specific conductivity became increasingly important over time. 
In 2018, the importance of each feature was more uniform across time. Air temperature was the dominant feature, followed by solar radiation, discharge, and wind speed. $\Delta$ temperature was somewhat important in the short-term.


- Feature importance for each  bay and year (Figure 4):
Air temperature, discharge, and specific conductivity were most important for AB17. For MB17, discharge was the most important feature for contemporaneous and short-term PC levels (0-1 days), while $\Delta$ temperature became increasingly dominant with increased time lag. Solar radiation and air temperature were also important in the mid-term (2-4 days). 
Discharge was the dominant feature throughout time in AB18, followed by solar radiation. Air temperature was the dominant feature throughout time in MB18, although $\Delta$ temperature and wind direction were important in the short-term (1 day out and 2 days out, respectively), wind speed was increasingly important with increased lag, and solar radiation was somewhat important throughout time.

- what we know right now is that 6 days out, pH is IMPORTANT for PC but the next step is figuring out if it's PREDICTIVE of a bloom --> need to build model 
- We got kinda hung up on the fact that there were parameters in the feature analysis results that were highly correlated with PC (response variable) but Easton reminded us that if our main goal is to predict a bloom, Chl or PC levels 6 days before is important to include if we are building a predictive model because that's still useful info ! Like it'd be great if we could predict if a bloom would start in 6 days just by knowing PC or Chl levels. 
- IMPORTANT POINT: there is a difference between mechanistic models and predictive models. Depending on how we decide to move forward (ie. which model we choose) we might not really need to understand the mechanisms driving the blooms because we might just try throwing all the data into a machine learning algorithm that tells us the relative predictive power of each of the parameters (I think...). 

## 5. Future Work (MC)

We could build on this work in a number of ways, by expanding our data set, correlating our phycocyanin measurements with satellite data or volunteer observations, identifying a bloom threshold, and most importantly, by using our high frequency data to create a forecasting model that could predict cyanobacteria blooms.

First, we could expand our data set by including cumulative degree days as another environmental variable, indicative of temperatures experienced throughout the season up to a given time point. We could collect mean daily temperatures for 2017 and 2018 for the nearest weather stations to the two bays from wunderground.com, and calculate the cumulative degrees above freezing (or above a biologically relevant temperature threshold such as 4&deg;C) for each day. We could then include this variable in analyses such as correlations, feature importance, or a forecasting model.

Second, we could correlate the buoys' measure of PC levels with other indicators of bloom presence such as volunteer observations and satellite data. There is an online data set publicly available with volunteer observations at the two bays: biweekly observations of bloom presence or absence throughout the 2017 and 2018 seasons. Comparing these observations with the daily average PC levels from our buoy sensors on the days of the observations could help us identify a threshold for what PC levels indicate a cyanobacteria bloom for management purposes. 

There is also satellite imagery available covering both bays, and it can be used to calculate a spectral index that's indicative of cyanobacteria presence. We could calculate this index at the position of each buoy for the time points of the available satellite imagery. We could then see how the index correlates with the daily average PC levels measured by the buoys, and examine whether there is a simple, consistent conversion between the two. If there are literature thresholds for what value of the spectral index constitutes a cyanobacteria bloom, we could then use a correlation or conversion to calculate an analogous bloom threshold for our buoy-measured PC levels. Having an accurate bloom threshold would be valuable for investigating bloom drivers and creating a forecasting model. It would give us the option to investigate continuous PC values directly, or convert them to categorical 'Bloom'/'No Bloom' data in case the later is easier to forecast or more strongly correlated with certain drivers.

Finally, our long term goal is to use this high frequency data to develop a forecasting model using machine learning techniques, in the hopes of predicting cyanobacteria blooms a few days before they occur. We would begin by inputting all available high frequency buoy, weather and discharge data, in order to predict PC levels (or a categorical variable for bloom presence or absence). If that proved successful, we would then begin to remove input variables one by one, to see what effect that has on the forecast accuracy. The goal would be to have a functional forecasting model with as few input variables as possible.

## Easton comments

Good job overall describing some background on the system and presenting interesting plots from your analyses. I think your future directions are great and that a lot could come out of this.

A few things to change for the final project:

- make sure the document can compile to a pdf or html
- include figure captions
- in your discussion bullet points, be sure to reference which figures support your claims

I look forward to providing more feedback after the final project and next semester. 

## 6. References 

INFO ON HOW TO CITE in .Rmd from https://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html : 

* Citations go inside square brackets and are separated by semicolons. Each citation must have a key, composed of ‘@’ + the citation identifier from the database, and may optionally have a prefix, a locator, and a suffix. Here are some examples:
  + Blah blah [@isles_modeling_2017].
* Then in Zotero create a `.BibTex` file by going to the library --> Export Library --> change to BibTex




